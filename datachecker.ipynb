{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from IPython.display import FileLink\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from tabulate import tabulate\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "\n",
    "import csv\n",
    "from io import StringIO\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Image, Paragraph\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Table, TableStyle, PageBreak, Spacer, Image, Frame, PageTemplate\n",
    "from reportlab.graphics.shapes import Drawing, Line\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# ignore group warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "warnings.filterwarnings(\"ignore\", 'This pattern is interpreted as a regular expression, and has match groups')\n",
    "\n",
    "# Add complete filepath here.\n",
    "filepath = sys.argv[1] if len(sys.argv) > 1 else ''\n",
    "# uncomment for local testing the following\n",
    "# filepath = \"./ProductionTradeSupplyFuelOil_MVP02_EF_20240712.csv\"\n",
    "zip = sys.argv[2].lower() == 'true' if len(sys.argv) > 2 else False\n",
    "\n",
    "filename = Path(filepath).stem\n",
    "folder_to_download = filename  # Use the same name as the CSV file you are feeding in. At the very bottom of the page, once the report is generated, a Zip file becomes available to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open docs/Geographies.csv and put values into a dataframe\n",
    "df_geography = pd.read_csv('./docs/Geographies.csv', delimiter=',', header=0)\n",
    "df_geography = df_geography['Shortname']\n",
    "\n",
    "# open docs/Units.csv and put values into a dataframe\n",
    "df_units = pd.read_csv('./docs/Units.csv', delimiter=',', header=0)\n",
    "df_units = df_units['Abbreviation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the JSON file and load columns into variables\n",
    "with open(\"docs/columns.json\", 'r') as json_file:\n",
    "    # Load the JSON data into a Python object\n",
    "    data = json.load(json_file)\n",
    "    universal_tabular_columns = data[\"universal_tabular_columns\"]\n",
    "    non_discerning_columns = data[\"non_discerning_columns\"]\n",
    "    df_mandatory_ef_columns = data[\"mandatory_columns_ef\"] # Emission Factors\n",
    "    df_mandatory_c_columns = data[\"mandatory_columns_cl\"] # Compositions\n",
    "\n",
    "# Open the JSON file and load graph repetition comparison into variables\n",
    "with open(\"docs/graph_repetition_comparison.json\", 'r') as json_file:\n",
    "    # Load the JSON data into a Python object\n",
    "    data = json.load(json_file)\n",
    "    graph_repetition = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_number_with_commas(number):\n",
    "    try:\n",
    "        # Ensure the number is an integer\n",
    "        number = int(number)\n",
    "        # Format the number with commas\n",
    "        return f\"{number:,}\"\n",
    "    except ValueError:\n",
    "        return \"Invalid number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(range_vals, percent_vals, graph_name, save_path):\n",
    "    # draw line graph where range_vals would be x values and percent_vals would be y values\n",
    "    import matplotlib.pyplot as plt\n",
    "    from itertools import zip_longest as zip\n",
    "\n",
    "    # Set the figure size and background color\n",
    "    plt.figure(figsize=(12, 8), facecolor='#131415')\n",
    "\n",
    "    # print for getting comparison values\n",
    "    # print(graph_name, range_vals, percent_vals)\n",
    "\n",
    "    # Draw line graph where range_vals would be x values and percent_vals would be y values\n",
    "    plt.plot(range(len(range_vals)), percent_vals, marker='s', color='#FFC80F',  zorder=5, linewidth=1, markersize=5)\n",
    "\n",
    "    # Draw the second line graph if provided\n",
    "    comparison_line = graph_repetition[graph_name]\n",
    "    second_range_vals = comparison_line[0]\n",
    "    second_percent_vals = comparison_line[1]\n",
    "    plt.plot(range(len(second_range_vals)), second_percent_vals, marker='s', color='#4C4C4D', zorder=4,linewidth=1, linestyle='dashed', markersize=10)\n",
    "\n",
    "    # Set the x-ticks to be evenly spaced indices\n",
    "    plt.xticks(range(len(range_vals)), [f\"{val} \\n ({percent*100:.1f}%)\" for val, percent in zip(range_vals, percent_vals)], color='#E9E9E9')\n",
    "\n",
    "    # Set the y-ticks with custom color\n",
    "    plt.yticks(color='#E9E9E9')\n",
    "\n",
    "    # Label the axes\n",
    "    plt.xlabel('Range Values',  color=(1., 1., 1., .65))\n",
    "    plt.ylabel('Percent',  color=(1., 1., 1., .65))\n",
    "\n",
    "    # Title of the plot\n",
    "    plt.title(graph_name, color=(1., 1., 1., .65))\n",
    "\n",
    "    # Set the grid color to white\n",
    "    plt.grid(True,  color='#2F3031')\n",
    "\n",
    "    # Set the background color of the plot area to black\n",
    "    plt.gca().set_facecolor('#131415')\n",
    "\n",
    "    # Remove the border around the graph\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "    # Set the y-axis limits to always be from 0 to 1\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "\n",
    "    # Set tick parameters to ensure visibility\n",
    "    # plt.tick_params(axis='x', color='#2F3031')\n",
    "    # plt.tick_params(axis='y', color='#2F3031')\n",
    "\n",
    "    # Save the plot to the specified path\n",
    "    plt.savefig(save_path, facecolor='#131415')\n",
    "\n",
    "    # Show the plot\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder path : /Users/kazkas/Desktop/T_CIRCA-Desktop/2024/CODE/DATACHECKER/ProductionTradeSupplyFuelOil_MVP02_EF_20240712\n"
     ]
    }
   ],
   "source": [
    "# change if there is an error reading csv or it is strangely formatted\n",
    "# df = pd.read_csv(filepath, on_bad_lines='skip')\n",
    "# df = pd.read_csv(filepath)\n",
    "df = pd.read_csv(filepath, engine=\"python\", encoding='utf-8', on_bad_lines='warn')\n",
    "# df = pd.read_csv(filepath, sep='delimiter', header=None)\n",
    "\n",
    "# add index to match the csv\n",
    "df.index += 2\n",
    "\n",
    "# print(df.columns)\n",
    "\n",
    "# set current date\n",
    "today = date.today()\n",
    "\n",
    "# YYmmdd\n",
    "CURRENT_DATE = today.strftime(\"%Y%m%d\")\n",
    "\n",
    "# CREATE FOLDERS\n",
    "# create a folder for each document\n",
    "FOLDER_NAME = re.sub(\"[^A-Z0-9]\", \" \", filename,0,re.IGNORECASE)\n",
    "FOLDER_NAME = re.sub(' +', '_', FOLDER_NAME)\n",
    "\n",
    "FOLDER_PATH = os.path.join(os.getcwd(), FOLDER_NAME)\n",
    "print(f'Folder path : {FOLDER_PATH}')\n",
    "if not os.path.exists(FOLDER_PATH):\n",
    "    os.mkdir(FOLDER_PATH)\n",
    "\n",
    "# formatting\n",
    "if not os.path.exists(f\"{FOLDER_PATH}/FORMATTING\"):\n",
    "    os.mkdir(f\"{FOLDER_PATH}/FORMATTING\")\n",
    "\n",
    "# repetition\n",
    "if not os.path.exists(f\"{FOLDER_PATH}/REPETITION\"):\n",
    "    os.mkdir(f\"{FOLDER_PATH}/REPETITION\")\n",
    "\n",
    "# other\n",
    "if not os.path.exists(f\"{FOLDER_PATH}/OTHER\"):\n",
    "    os.mkdir(f\"{FOLDER_PATH}/OTHER\")\n",
    "\n",
    "# PRINT TABLE\n",
    "MASTER_TABLE = \"\"\n",
    "CMD_TABLE= []\n",
    "def add_to_cmd_table(name, value, mandatory=False):\n",
    "    global CMD_TABLE\n",
    "    if mandatory:\n",
    "        value = \"\\033[1;31;40m\" + value + \"\\033[0m\"\n",
    "    CMD_TABLE.append([name, value])\n",
    "\n",
    "def print_table(table, horizontal, column_headers = []):\n",
    "    global MASTER_TABLE\n",
    "    tab = None\n",
    "    if horizontal:\n",
    "        tab = PrettyTable(table[0])\n",
    "        tab.add_rows(table[1:])\n",
    "    else:\n",
    "        tab = PrettyTable()\n",
    "        for index, item in enumerate(column_headers):\n",
    "            tab.add_column(item, table[index])\n",
    "    tab.padding_width = 2\n",
    "    tab.junction_char = '.'\n",
    "    # print(tab)\n",
    "    MASTER_TABLE += tab.get_csv_string()\n",
    "    MASTER_TABLE += \"-\\n\"\n",
    "    MASTER_TABLE += \"-\\n\"\n",
    "    MASTER_TABLE += \"-\\n\"\n",
    "\n",
    "# print(df.iloc[df.shape[0]-1])\n",
    "# print(df.shape[0])\n",
    "# # Drop rows with any empty cells // put more threshold to kick the strange ones\n",
    "# df.dropna(how='all',thresh=1, inplace=True)\n",
    "# print(df.shape[0])\n",
    "\n",
    "MASTER_TABLE += \"Total data points\\n\"\n",
    "MASTER_TABLE += f\"{df.shape[0]}\\n\"\n",
    "MASTER_TABLE += \"-\\n\"\n",
    "MASTER_TABLE += \"-\\n\"\n",
    "MASTER_TABLE += \"-\\n\"\n",
    "\n",
    "# print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether existing columns are in the same names as universal tabular columns\n",
    "for index, item in enumerate(df.columns):\n",
    "    if item not in universal_tabular_columns:\n",
    "        print(f'this is not the right name : {item}')\n",
    "\n",
    "# add missing columns \n",
    "for index, item in enumerate(universal_tabular_columns):\n",
    "    if item not in df.columns:\n",
    "        print(f'the column was added : {item}')\n",
    "        # df[item] = pd.Series()\n",
    "        df[item] = pd.Series(dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_incorrect():\n",
    "    # make the data incorrect\n",
    "    df.loc[7,'Source'] = None\n",
    "    df.loc[7,'Value'] = \"12\"\n",
    "    df.loc[7,'Name'] = \"$$ test\"\n",
    "    df.loc[7,'Description'] = \"test  this\"\n",
    "    df.loc[8,'Name'] = \"test this?\"\n",
    "\n",
    "    # duplication\n",
    "    for index, item in enumerate(df.columns):\n",
    "        df.loc[4,item] = df.loc[3,item]\n",
    "\n",
    "    # non discenrning\n",
    "    for index, item in enumerate(df.columns):\n",
    "        if item in non_discerning_columns:\n",
    "            df.loc[5,item] = df.loc[4,item]\n",
    "\n",
    "    # nan values\n",
    "    df.loc[2, 'Name'] = np.nan\n",
    "    df.loc[2, 'Description'] = np.nan\n",
    "\n",
    "# make_data_incorrect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicates_non_discerning(dataFrame, df_columns, table_text, analyse_name):\n",
    "    global MASTER_TABLE\n",
    "    # finds all duplicate rows and keeps all of them\n",
    "    df_local = dataFrame[df_columns]\n",
    "    df_range = df_local[df_local.duplicated(keep=False)]\n",
    "\n",
    "    # sort based on the first column\n",
    "    df_range = df_range.sort_values(by=[df_columns[0]])\n",
    "\n",
    "    # total dataframe count\n",
    "    df_count = dataFrame.shape[0]\n",
    "    \n",
    "    # Number of instances\n",
    "    df_instance_count = df_range.shape[0]\n",
    "\n",
    "    # Number of records that would be removed\n",
    "    df_without_range = df_local.drop_duplicates()\n",
    "    df_range_count = df_count - df_without_range.shape[0]\n",
    "\n",
    "    # - % of total data affected (copies/total)\n",
    "    df_range_percent = df_range_count / df_count\n",
    "\n",
    "    # print(f\"{analyse_name}\")\n",
    "    MASTER_TABLE += f\"{analyse_name}\\n\"\n",
    "\n",
    "    # if there are no values exit\n",
    "    if df_range_percent == 0:\n",
    "        MASTER_TABLE += \"PASS\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        add_to_cmd_table(analyse_name, \"PASS\")\n",
    "        return\n",
    "    add_to_cmd_table(analyse_name, \"FIX\", True)\n",
    "    \n",
    "    table = [table_text, [df_instance_count, df_range_count, df_range_percent]]\n",
    "    print_table(table, True)\n",
    "\n",
    "    # SAVE FILES\n",
    "    # save - Rows that are duplicated - OUTPUT 1\n",
    "    df_range_full_table = dataFrame.loc[df_range.index]\n",
    "    df_range_full_table.to_csv(f'{FOLDER_PATH}/OTHER/Report-{analyse_name}-Output_1-{filename}-{CURRENT_DATE}.csv',encoding='utf-8')\n",
    "    \n",
    "    # print(f\"Saved â€” {analyse_name}-Report-Output_1\")\n",
    "\n",
    "    # save - Duplicate instances & number of each - OUTPUT 2\n",
    "    # count the duplicates\n",
    "    df_range_group = df_range.groupby(df_range.columns.tolist(),as_index=False, dropna=False, sort=True).size()\n",
    "    # add count to begining\n",
    "    df_range_group.insert(0, \"count\", df_range_group[\"size\"])\n",
    "    # remove size at the end\n",
    "    df_range_group.pop('size')\n",
    "    # sort values by count\n",
    "    df_range_group = df_range_group.sort_values(by=\"count\", ascending=False)\n",
    "    # reset index\n",
    "    df_range_group = df_range_group.reset_index(drop=True)\n",
    "    # save\n",
    "    df_range_group.to_csv(f'{FOLDER_PATH}/OTHER/Report-{analyse_name}-Output_2-{filename}-{CURRENT_DATE}.csv',encoding='utf-8')\n",
    "\n",
    "# DUPLICATES\n",
    "table_text = ['Number of instances', 'Number of records that would be removed', '% of total data affected (copies/total)']\n",
    "duplicates_non_discerning(df, df.columns, table_text, \"Duplication\")\n",
    "\n",
    "# drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# NON DISCERNING-INFO\n",
    "table_text = ['Number of instances', 'Number of records that indiscernable', '% of rows of the total data affected (copies/total)']\n",
    "duplicates_non_discerning(df, non_discerning_columns, table_text, \"Non_discerning_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value(dataFrame):\n",
    "    global MASTER_TABLE\n",
    "\n",
    "    # total dataframe count\n",
    "    df_count = dataFrame.shape[0]\n",
    "\n",
    "    def change_missing_values(mvv):\n",
    "        mvv_changed = []\n",
    "        for i in mvv:\n",
    "            val = i\n",
    "            if i == 0:\n",
    "                val = \"full\"\n",
    "            elif i == df_count:\n",
    "                val = \"---\"\n",
    "            mvv_changed.append(val)\n",
    "                \n",
    "        return mvv_changed\n",
    "\n",
    "    # check whether it is emmission factor or composition\n",
    "    if dataFrame[\"Value\"].isna().sum() == df_count:\n",
    "        df_mandatory_columns= df_mandatory_c_columns\n",
    "    else:\n",
    "        df_mandatory_columns= df_mandatory_ef_columns\n",
    "    df_optional = dataFrame.drop(columns = df_mandatory_columns) # mandatory dataframe\n",
    "    df_mandatory = dataFrame[df_mandatory_columns] # mandatory dataframe\n",
    "    \n",
    "    # MANDATORY\n",
    "    missing_value_table = df_mandatory.isna().sum()\n",
    "    missing_value_values = change_missing_values(missing_value_table.tolist())\n",
    "    \n",
    "    # save misisng value table\n",
    "    MASTER_TABLE += f\"Missing_value_mandatory\\n\"\n",
    "\n",
    "    # if it does not miss any values\n",
    "    if len([x for x in missing_value_values if x != \"full\"]) == 0:\n",
    "        MASTER_TABLE += \"PASS\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        add_to_cmd_table(\"Missing_value_mandatory\", \"PASS\")\n",
    "    else:\n",
    "        table = [missing_value_table.index.tolist(), missing_value_values]\n",
    "        print_table(table, False, [\"Column\", \"Count\"])\n",
    "        add_to_cmd_table(\"Missing_value_mandatory\", \"FIX\", True)\n",
    "\n",
    "        # go trough each column in the dataFrame and check which columns misses somve values. If it does, save the document\n",
    "        for col_name, val in missing_value_table.items():\n",
    "            if val != dataFrame.shape[0] and val != 0:\n",
    "                cn = re.sub(\"[^A-Z]\", \" \", col_name,0,re.IGNORECASE)\n",
    "                cn = re.sub(' +', '_', cn)\n",
    "                fname = f'{FOLDER_PATH}/OTHER/Report-Missing_value_mandatory-{cn}-Output_1-{filename}-{CURRENT_DATE}.csv'\n",
    "                df_isna = dataFrame[dataFrame[col_name].isna()]\n",
    "                df_isna.to_csv(fname,encoding='utf-8')\n",
    "    \n",
    "    # OPTIONAL\n",
    "    missing_value_table = df_optional.isna().sum()\n",
    "    missing_value_values = change_missing_values(missing_value_table.tolist())\n",
    "    \n",
    "    # save misisng value table\n",
    "    MASTER_TABLE += f\"Missing_value_optional\\n\"\n",
    "\n",
    "    # if it does not miss any values\n",
    "    table = [missing_value_table.index.tolist(), missing_value_values]\n",
    "    print_table(table, False, [\"Column\", \"Count\"])\n",
    "\n",
    "    # go trough each column in the dataFrame and check which columns misses somve values. If it does, save the document\n",
    "    for col_name, val in missing_value_table.items():\n",
    "        if val != dataFrame.shape[0] and val != 0:\n",
    "            cn = re.sub(\"[^A-Z]\", \" \", col_name,0,re.IGNORECASE)\n",
    "            cn = re.sub(' +', '_', cn)\n",
    "            fname = f'{FOLDER_PATH}/OTHER/Report-Missing_value_optional-{cn}-Output_1-{filename}-{CURRENT_DATE}.csv'\n",
    "            df_isna = dataFrame[dataFrame[col_name].isna()]\n",
    "            df_isna.to_csv(fname,encoding='utf-8')\n",
    "\n",
    "\n",
    "missing_value(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repetition(dataFrame, df_columns, table_text, analyse_name):\n",
    "    global MASTER_TABLE\n",
    "    # finds all duplicate rows and keeps all of them\n",
    "    df_local = dataFrame[df_columns]\n",
    "    df_range = df_local[df_local.duplicated(keep=False)]\n",
    "\n",
    "    # sort based on the first column\n",
    "    df_range = df_range.sort_values(by=[df_columns[0]])\n",
    "\n",
    "    # total dataframe count\n",
    "    df_count = dataFrame.shape[0]\n",
    "\n",
    "    # count the duplicates\n",
    "    df_range_group = df_range.groupby(df_range.columns.tolist(),as_index=False, dropna=False, sort=True).size()\n",
    "    # sort values by count\n",
    "    df_range_group = df_range_group.sort_values(by=\"size\", ascending=False)\n",
    "    # reset index\n",
    "    df_range_group = df_range_group.reset_index(drop=True)\n",
    "\n",
    "    # print \n",
    "    MASTER_TABLE += f\"{analyse_name}\\n\"\n",
    "    MASTER_TABLE += f\"{table_text}\\n\"\n",
    "\n",
    "    # if there are no values exit\n",
    "    if df_range_group.shape[0] == 0:\n",
    "        MASTER_TABLE += \"PASS\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        add_to_cmd_table(analyse_name, \"PASS\")\n",
    "        return\n",
    "    \n",
    "    add_to_cmd_table(analyse_name, \"FIX\")\n",
    "\n",
    "    # go trough the range and add it to the list\n",
    "    df_range_vals = [2,5,10,25,50,100,1000,10000]\n",
    "    df_total = []\n",
    "    df_instances = []\n",
    "    df_percent = []\n",
    "    for index, value in enumerate(df_range_vals):\n",
    "        partition_of_data = df_range_group[df_range_group[\"size\"] >= value]\n",
    "        partition_of_data_total = partition_of_data.sum()[\"size\"]\n",
    "        partition_of_data_instances = len(partition_of_data[\"size\"])\n",
    "        partition_of_data_percent = partition_of_data_total/df_count\n",
    "\n",
    "        df_total.append(partition_of_data_total)\n",
    "        df_instances.append(partition_of_data_instances)\n",
    "        df_percent.append(partition_of_data_percent)\n",
    "\n",
    "    table = [df_range_vals,df_total,df_instances,df_percent]\n",
    "    print_table(table, False, [\"more or equal to copies \", \"data affected\", \"instance count\", \"percent\"])\n",
    "\n",
    "    draw_graph(df_range_vals, df_percent, f'{analyse_name} | {table_text}', f'{FOLDER_PATH}/REPETITION/Report-{analyse_name}-Output_2-{filename}-{CURRENT_DATE}.png')   \n",
    "\n",
    "    # SAVE FILES\n",
    "    # save - Rows that are duplicated - OUTPUT 1\n",
    "    df_range_full_table = dataFrame.loc[df_range.index]\n",
    "    df_range_full_table.to_csv(f'{FOLDER_PATH}/REPETITION/Report-{analyse_name}-Output_1-{filename}-{CURRENT_DATE}.csv',encoding='utf-8')\n",
    "\n",
    "    # save - Duplicate instances & number of each - OUTPUT 2\n",
    "    # count the duplicates\n",
    "    df_range_group = df_range.groupby(df_range.columns.tolist(),as_index=False, dropna=False, sort=True).size()\n",
    "    # add count to begining\n",
    "    df_range_group.insert(0, \"count\", df_range_group[\"size\"])\n",
    "    # remove size at the end\n",
    "    df_range_group.pop('size')\n",
    "    # sort values by count\n",
    "    df_range_group = df_range_group.sort_values(by=\"count\", ascending=False)\n",
    "    # reset index\n",
    "    df_range_group = df_range_group.reset_index(drop=True)\n",
    "    # save\n",
    "    df_range_group.to_csv(f'{FOLDER_PATH}/REPETITION/Report-{analyse_name}-Output_2-{filename}-{CURRENT_DATE}.csv',encoding='utf-8')\n",
    "\n",
    "# REPETITION 1\n",
    "table_text = 'The Name instance'\n",
    "repetition(df, [\"Name\"], table_text, \"Repetition_1\")\n",
    "\n",
    "# REPETITION 2\n",
    "table_text = 'The Description instance'\n",
    "repetition(df, [\"Description\"], table_text, \"Repetition_2\")\n",
    "\n",
    "try:\n",
    "    # if (df[[\"Components\"]].isna().sum() == df.shape[0]).bool() == False:\n",
    "    if (df[[\"Components\"]].isnull().sum() == df.shape[0]).all() == False:\n",
    "        # REPETITION 3\n",
    "        table_text = 'The Comp. Items List instance'\n",
    "        repetition(df, [\"Components\"], table_text, \"Repetition_3\")\n",
    "    else:\n",
    "        # REPETITION 4\n",
    "        table_text = 'The Value instance'\n",
    "        repetition(df, [\"Value\"], table_text, \"Repetition_4\")\n",
    "except:\n",
    "    print(\"The dataset does not include all columns\")\n",
    "\n",
    "    # REPETITION 4\n",
    "    table_text = 'The Value instance'\n",
    "    repetition(df, [\"Value\"], table_text, \"Repetition_4\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_2(dataFrame, df_columns, analyse_name, description_text):\n",
    "    global MASTER_TABLE\n",
    "    \n",
    "    def check_numbers(item):\n",
    "        row = item[df_columns[0]]\n",
    "        if not isinstance(row,float) and not isinstance(row,int) and not isinstance(row, np.int64):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    df_local = dataFrame[df_columns]\n",
    "\n",
    "    df_results = df_local[df_local.apply(check_numbers, axis=1)]\n",
    "\n",
    "    # check upper case\n",
    "    count = df_results.shape[0]\n",
    "    indexes = df_results.index\n",
    "\n",
    "    # count percent\n",
    "    df_percent = count / df_local.shape[0]\n",
    "\n",
    "    # print table\n",
    "    MASTER_TABLE += f\"{analyse_name}\\n\"\n",
    "    MASTER_TABLE += f\"{description_text}\\n\"\n",
    "    \n",
    "    # if there are no values exit\n",
    "    if df_percent == 0:\n",
    "        MASTER_TABLE += \"PASS\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "\n",
    "        add_to_cmd_table(analyse_name, \"PASS\")\n",
    "        return\n",
    "    \n",
    "    add_to_cmd_table(analyse_name, \"FIX\", True)\n",
    "\n",
    "    # table = [[\"of rows where the Value column items does not contain a number\"],[f\"{format_number_with_commas(count)}/{format_number_with_commas(df_local.shape[0])} | {df_percent}\"]]\n",
    "    # print_table(table, True)\n",
    "\n",
    "    table = [[df_columns[0]], [df_percent], [count]]\n",
    "    print_table(table, False, [\"Column\", \"Percentage\", \"Count\"])\n",
    "\n",
    "    # save document\n",
    "    df_full_table = dataFrame.loc[indexes]\n",
    "    df_full_table.to_csv(f'{FOLDER_PATH}/FORMATTING/Report-{analyse_name}-Output_1-{filename}-{CURRENT_DATE}.csv',encoding='utf-8')\n",
    "            \n",
    "format_2(df, [\"Value\"], \"Formatting_2\", \"of rows where the Value column items does not contain a number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_all_columns(dataFrame, df_columns, regex, analyse_name, description_text):\n",
    "    global MASTER_TABLE\n",
    "\n",
    "    # drop source as it always has double characters\n",
    "    df_local = dataFrame[df_columns].drop(\"Source\", axis=1)\n",
    "\n",
    "    indexes = []\n",
    "    output_count = []\n",
    "\n",
    "    # go trough columns and check whether in any of those there is a questionmark\n",
    "    for index, item in enumerate(df_local.columns):\n",
    "        # stringify the column\n",
    "        # temp = dataFrame[item].astype(str).str.replace('.', '', regex=True)\n",
    "        temp = dataFrame[item].astype(str)\n",
    "        search_range = temp[temp.str.contains(regex)]\n",
    "        \n",
    "        # set indexes to search range ndexes\n",
    "        indexes = search_range.index.tolist()\n",
    "\n",
    "        # append to output count\n",
    "        output_count.append(str(len(indexes)))\n",
    "\n",
    "        # save file if found\n",
    "        if len(indexes) > 0:\n",
    "            # create a file name\n",
    "            cn = re.sub(\"[^A-Z]\", \" \", item,0,re.IGNORECASE)\n",
    "            cn = re.sub(' +', '_', cn)\n",
    "\n",
    "            # save document\n",
    "            df_full_table = dataFrame.loc[indexes]\n",
    "            df_full_table.to_csv(f'{FOLDER_PATH}/FORMATTING/Report-{analyse_name}-{cn}-Output_1-{filename}-{CURRENT_DATE}.csv',encoding='utf-8')\n",
    "\n",
    "    # calculate percentages\n",
    "    output_percentages = [int(i) / df_local.shape[0] for i in output_count]\n",
    "\n",
    "    # print table\n",
    "    MASTER_TABLE += f\"{analyse_name}\\n\"\n",
    "    MASTER_TABLE += f\"{description_text}\\n\"\n",
    "\n",
    "    # if there are no values exit\n",
    "    if  len([x for x in output_count if int(x) != 0]) == 0:\n",
    "        MASTER_TABLE += \"PASS\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        add_to_cmd_table(analyse_name, \"PASS\")\n",
    "        return\n",
    "    \n",
    "    add_to_cmd_table(analyse_name, \"FIX\", True)\n",
    "\n",
    "    # Convert output_count from strings to integers\n",
    "    # output_count = [int(count) for count in output_count]\n",
    "\n",
    "    # Get indexes where output_count is 1\n",
    "    indexes_with_one = [index for index, count in enumerate(output_count) if int(count) > 0]\n",
    "\n",
    "    # Filter percentages, counts, and columns by these indexes\n",
    "    filtered_percentages = [output_percentages[index] for index in indexes_with_one]\n",
    "    filtered_counts = [output_count[index] for index in indexes_with_one]\n",
    "    filtered_columns = [df_local.columns[index] for index in indexes_with_one]\n",
    "\n",
    "    table = [filtered_columns, filtered_percentages, filtered_counts]\n",
    "    # print(table)\n",
    "    \n",
    "    # table = [df_local.columns.tolist(), output_percentages, output_count]\n",
    "    print_table(table, False, [\"Column\", \"Percentage\", \"Count\"])\n",
    "\n",
    "regex = r\"([^A-Za-z0-9 ])\\1\"\n",
    "description_text = \"% of rows with a doubled character that is not a letter or number in any column & count\"\n",
    "format_all_columns(df, df.columns, regex, \"Formatting_3\", description_text)\n",
    "\n",
    "regex = r\"([ ])\\1\"\n",
    "description_text = \"% of rows with a doubled space in any column & count\"\n",
    "format_all_columns(df, df.columns, regex, \"Formatting_4\",description_text)\n",
    "\n",
    "regex = r\"([?])\"\n",
    "description_text = \"% of rows with a question mark in any column & count\"\n",
    "format_all_columns(df, df.columns, regex, \"Formatting_5\",description_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_6(dataFrame, df_columns, analyse_name, description_text):\n",
    "    global MASTER_TABLE\n",
    "    \n",
    "    # check whether df_local contains a value from df_geographies \n",
    "    def check_geography(item):\n",
    "        try:\n",
    "            row = item[df_columns[0]]\n",
    "            if row not in df_geography.values:\n",
    "                return True\n",
    "            return False\n",
    "        except:\n",
    "            print(f\"Exception, inspect it : {item}\")\n",
    "            return True\n",
    "\n",
    "    # take only the columns that are needed\n",
    "    df_local = dataFrame[df_columns]\n",
    "\n",
    "    df_results = df_local[df_local.apply(check_geography, axis=1)]\n",
    "\n",
    "    # check upper case\n",
    "    count = df_results.shape[0]\n",
    "    indexes = df_results.index\n",
    "\n",
    "    # count percent\n",
    "    df_percent = count / df_local.shape[0]\n",
    "\n",
    "    # print table\n",
    "    MASTER_TABLE += f\"{analyse_name}\\n\"\n",
    "    MASTER_TABLE += f\"{description_text}\\n\"\n",
    "    \n",
    "    # if there are no values exit\n",
    "    if count == 0:\n",
    "        MASTER_TABLE += \"of rows not in geograpies list\\n\"\n",
    "        MASTER_TABLE += \"PASS\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "\n",
    "        add_to_cmd_table(analyse_name, \"PASS\")\n",
    "        return\n",
    "    \n",
    "    add_to_cmd_table(analyse_name, \"FIX\", True)\n",
    "    \n",
    "    # table = [[\"of rows not in geograpies list\"],[f\"{format_number_with_commas(count)} / {format_number_with_commas(df_local.shape[0])} | {df_percent}\"]]\n",
    "    # print_table(table, True)\n",
    "\n",
    "    table = [[df_columns[0]], [df_percent], [count]]\n",
    "    print_table(table, False, [\"Column\", \"Percentage\", \"Count\"])\n",
    "\n",
    "    # save document\n",
    "    df_full_table = dataFrame.loc[indexes]\n",
    "    df_full_table.to_csv(f'{FOLDER_PATH}/FORMATTING/Report-{analyse_name}-Output_1-{filename}-{CURRENT_DATE}.csv',encoding='utf-8')\n",
    "\n",
    "\n",
    "if (df[[\"Region/Regional Scope\"]].isnull().sum() == df.shape[0]).all() == False:            \n",
    "    format_6(df, [\"Region/Regional Scope\"], \"Formatting_6\", \"of rows not in geograpies list\")\n",
    "else:\n",
    "    print(\"No Region/Regional Scope\")\n",
    "    # print table\n",
    "    MASTER_TABLE += \"Formatting_6\\n\"\n",
    "    MASTER_TABLE += \"of rows not in geograpies list\\n\"\n",
    "    MASTER_TABLE += \"No Region/Regional Scope \\n\"\n",
    "    MASTER_TABLE += \"-\\n\"\n",
    "    MASTER_TABLE += \"-\\n\"\n",
    "    MASTER_TABLE += \"-\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_7(dataFrame, df_columns, analyse_name, description_text):\n",
    "    global MASTER_TABLE\n",
    "    \n",
    "    # check whether df_local contains a value from df_geographies \n",
    "    def check_date(item):\n",
    "        try:\n",
    "            row = str(item[df_columns[0]])  # Convert the value to a string\n",
    "            # Define regex patterns for yyyy-dd-mm and yyyy\n",
    "            pattern_yyyy_dd_mm = re.compile(r'^\\d{4}-\\d{2}-\\d{2}$')\n",
    "            pattern_yyyy = re.compile(r'^\\d{4}$')\n",
    "            \n",
    "            # Check if the row matches either pattern\n",
    "            if not (pattern_yyyy_dd_mm.match(row) or pattern_yyyy.match(row)):\n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Exception, inspect it : {item}, Error: {e}\")\n",
    "            return True\n",
    "\n",
    "    # take only the columns that are needed\n",
    "    df_local = dataFrame[df_columns]\n",
    "\n",
    "    df_results = df_local[df_local.apply(check_date, axis=1)]\n",
    "\n",
    "    # check upper case\n",
    "    count = df_results.shape[0]\n",
    "    indexes = df_results.index\n",
    "\n",
    "    # count percent\n",
    "    df_percent = count / df_local.shape[0]\n",
    "\n",
    "    # print table\n",
    "    MASTER_TABLE += f\"{analyse_name}\\n\"\n",
    "    MASTER_TABLE += f\"{description_text}\\n\"\n",
    "    \n",
    "    # if there are no values exit\n",
    "    if count == 0:\n",
    "        MASTER_TABLE += \"of rows not in correct date format\\n\"\n",
    "        MASTER_TABLE += \"PASS\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "\n",
    "        add_to_cmd_table(analyse_name, \"PASS\")\n",
    "        return\n",
    "    \n",
    "    add_to_cmd_table(analyse_name, \"FIX\", True)\n",
    "    \n",
    "    # table = [[\"of rows not in correct date format\"],[f\"{format_number_with_commas(count)} / {format_number_with_commas(df_local.shape[0])} | {df_percent}\"]]\n",
    "    # print_table(table, True)\n",
    "    \n",
    "    table = [[df_columns[0]], [df_percent], [count]]\n",
    "    print_table(table, False, [\"Column\", \"Percentage\", \"Count\"])\n",
    "\n",
    "    # save document\n",
    "    df_full_table = dataFrame.loc[indexes]\n",
    "    df_full_table.to_csv(f'{FOLDER_PATH}/FORMATTING/Report-{analyse_name}-Output_1-{filename}-{CURRENT_DATE}.csv',encoding='utf-8')\n",
    "\n",
    "\n",
    "if (df[[\"Sample/Representative Date\"]].isnull().sum() == df.shape[0]).all() == False:            \n",
    "    format_7(df, [\"Sample/Representative Date\"], \"Formatting_7\", \"of rows not in correct date format\")\n",
    "else:\n",
    "    print(\"No Sample/Representative Date\")\n",
    "    # print table\n",
    "    MASTER_TABLE += \"Formatting_7\\n\"\n",
    "    MASTER_TABLE += \"of rows not in correct date format\\n\"\n",
    "    MASTER_TABLE += \"No Sample/Representative Date \\n\"\n",
    "    MASTER_TABLE += \"-\\n\"\n",
    "    MASTER_TABLE += \"-\\n\"\n",
    "    MASTER_TABLE += \"-\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_8(dataFrame, df_columns, analyse_name, description_text):\n",
    "    global MASTER_TABLE\n",
    "    \n",
    "    # check whether df_local contains a value from df_units \n",
    "    def check_unit(item):\n",
    "        try:\n",
    "            row = item[df_columns[0]]\n",
    "            if row not in df_units.values:\n",
    "                return True\n",
    "            return False\n",
    "        except:\n",
    "            print(f\"Exception, inspect it : {item}\")\n",
    "            return True\n",
    "\n",
    "    # take only the columns that are needed\n",
    "    df_local = dataFrame[df_columns]\n",
    "\n",
    "    df_results = df_local[df_local.apply(check_unit, axis=1)]\n",
    "\n",
    "    # check upper case\n",
    "    count = df_results.shape[0]\n",
    "    indexes = df_results.index\n",
    "\n",
    "    # count percent\n",
    "    df_percent = count / df_local.shape[0]\n",
    "\n",
    "    # print table\n",
    "    MASTER_TABLE += f\"{analyse_name}\\n\"\n",
    "    MASTER_TABLE += f\"{description_text}\\n\"\n",
    "    \n",
    "    # if there are no values exit\n",
    "    if count == 0:\n",
    "        MASTER_TABLE += \"of rows not in correct unit format\\n\"\n",
    "        MASTER_TABLE += \"PASS\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "        MASTER_TABLE += \"-\\n\"\n",
    "\n",
    "        add_to_cmd_table(analyse_name, \"PASS\")\n",
    "        return\n",
    "    \n",
    "    add_to_cmd_table(analyse_name, \"FIX\", True)\n",
    "    \n",
    "    # table = [[\"of rows not in correct unit format\"],[f\"{format_number_with_commas(count)}/{format_number_with_commas(df_local.shape[0])} | {df_percent}\"]]\n",
    "    # print_table(table, True)\n",
    "\n",
    "    table = [[df_columns[0]], [df_percent], [count]]\n",
    "    print_table(table, False, [\"Column\", \"Percentage\", \"Count\"])\n",
    "\n",
    "    # save document\n",
    "    df_full_table = dataFrame.loc[indexes]\n",
    "    df_full_table.to_csv(f'{FOLDER_PATH}/FORMATTING/Report-{analyse_name}-Output_1-{filename}-{CURRENT_DATE}.csv',encoding='utf-8')\n",
    "\n",
    "\n",
    "if (df[[\"Unit\"]].isnull().sum() == df.shape[0]).all() == False:            \n",
    "    format_8(df, [\"Unit\"], \"Formatting_8\", \"of rows not in correct unit format\")\n",
    "else:\n",
    "    print(\"No Units\")\n",
    "    # print table\n",
    "    MASTER_TABLE += \"Formatting_8\\n\"\n",
    "    MASTER_TABLE += \"of rows not in correct unit format\\n\"\n",
    "    MASTER_TABLE += \"No Units \\n\"\n",
    "    MASTER_TABLE += \"-\\n\"\n",
    "    MASTER_TABLE += \"-\\n\"\n",
    "    MASTER_TABLE += \"-\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table ():\n",
    "    global MASTER_TABLE\n",
    "    fname = f'{FOLDER_PATH}/Report-{filename}-{CURRENT_DATE}.csv'\n",
    "    with open(f'{fname}', 'w', newline='') as f_output:\n",
    "        f_output.write(MASTER_TABLE)\n",
    "save_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pdf():\n",
    "    global MASTER_TABLE\n",
    "    fname = f'{FOLDER_PATH}/Report-{filename}-{CURRENT_DATE}.pdf'\n",
    "    \n",
    "    # Parse the CSV data in MASTER_TABLE\n",
    "    csv_data = StringIO(MASTER_TABLE)\n",
    "    reader = csv.reader(csv_data)\n",
    "    all_rows = [row for row in reader]  # Read all rows into a list\n",
    "    \n",
    "    # Split data into separate tables based on the separator\n",
    "    tables = []\n",
    "    current_table = []\n",
    "    for row in all_rows:\n",
    "        if row == [\"-\"]:\n",
    "            if current_table:\n",
    "                tables.append(current_table)\n",
    "                current_table = []\n",
    "        else:\n",
    "            current_table.append(row)\n",
    "    if current_table:\n",
    "        tables.append(current_table)\n",
    "    \n",
    "    # Create a PDF document\n",
    "    pdf = SimpleDocTemplate(fname, pagesize=letter)\n",
    "    elements = []\n",
    "    styles = getSampleStyleSheet()\n",
    "    \n",
    "    # Define custom styles for headline and subheadline\n",
    "    error_style = ParagraphStyle(\n",
    "        name='Headline', \n",
    "        parent=styles['Heading2'], \n",
    "        fontName='Helvetica-Bold',\n",
    "        textColor= colors.HexColor(\"#FFC80F\"),  # Set the line color to gray\n",
    "        fontSize=10, \n",
    "        spaceBefore=16, \n",
    "        spaceAfter=8\n",
    "    )\n",
    "\n",
    "    headline_style = ParagraphStyle(\n",
    "        name='Headline', \n",
    "        parent=styles['Heading2'], \n",
    "        fontName='Helvetica-Bold',\n",
    "        textColor= colors.HexColor(\"#E9E9E9\"),  # Set the line color to gray\n",
    "        fontSize=10, \n",
    "        spaceBefore=16, \n",
    "        spaceAfter=8\n",
    "    )\n",
    "    subheadline_style = ParagraphStyle(\n",
    "        name='Subheadline', \n",
    "        parent=styles['Heading3'], \n",
    "        fontName='Helvetica',\n",
    "        textColor= colors.HexColor(\"#B1B1B1\"),  # Set the line color to gray\n",
    "        fontSize=10, \n",
    "        spaceBefore=8, \n",
    "        spaceAfter=8\n",
    "    )\n",
    "\n",
    "    pass_style = ParagraphStyle(\n",
    "        name='Pass', \n",
    "        parent=styles['BodyText'], \n",
    "        fontSize=10, \n",
    "        textColor= colors.HexColor(\"#B1B1B1\"),  # Set the line color to gray\n",
    "        fontName='Helvetica',\n",
    "        spaceBefore=8,\n",
    "        spaceAfter=8,\n",
    "    )\n",
    "\n",
    "    body_style = ParagraphStyle(\n",
    "        name='Pass', \n",
    "        parent=styles['BodyText'], \n",
    "        fontSize=10, \n",
    "        textColor= colors.HexColor(\"#E9E9E9\"),  # Set the line color to gray\n",
    "        fontName='Helvetica',\n",
    "        spaceBefore=8,\n",
    "        spaceAfter=8,\n",
    "    )\n",
    "\n",
    "    body_style_err = ParagraphStyle(\n",
    "        name='Pass', \n",
    "        parent=styles['BodyText'], \n",
    "        fontSize=10, \n",
    "        textColor= colors.HexColor(\"#FFC80F\"),  # Set the line color to gray\n",
    "        fontName='Helvetica',\n",
    "        spaceBefore=8,\n",
    "        spaceAfter=8,\n",
    "    )\n",
    "\n",
    "    # Create Table objects for each table and add them to the PDF\n",
    "    for i, table_data in enumerate(tables):\n",
    "        if table_data:\n",
    "            # Treat the first row as a headline\n",
    "            headline = table_data[0]\n",
    "\n",
    "            if \"Repetition\" in headline[0] or \"Formatting_2\" in headline[0] or \"Missing_value_mandatory\" in headline[0] or \"Missing_value_optional\" in headline[0]:\n",
    "                elements.append(PageBreak())  # Add a new page\n",
    "            \n",
    "            # Check if the second row is a subheadline\n",
    "            if len(table_data) > 1 and len(table_data[1]) == 1:\n",
    "                subheadline = table_data[1]\n",
    "\n",
    "                if subheadline == [\"PASS\"]:\n",
    "                    elements.append(Paragraph(\" \".join(headline), headline_style))\n",
    "                    elements.append(Paragraph(\" \".join(subheadline), pass_style))\n",
    "                else:\n",
    "                    # only error in non total data points or repetition\n",
    "                    if \"Formatting\" in headline[0] and table_data[2] != [\"PASS\"]:\n",
    "                        elements.append(Paragraph(\" \".join(headline), error_style))\n",
    "                    elif \"Duplication\" in headline[0]:\n",
    "                        elements.append(Paragraph(\" \".join(headline), error_style))\n",
    "                    else:\n",
    "                        elements.append(Paragraph(\" \".join(headline), headline_style))\n",
    "                        pass\n",
    "                    elements.append(Paragraph(\" \".join(subheadline), subheadline_style))\n",
    "                table_data = table_data[2:]  # Remove headline and subheadline rows\n",
    "                \n",
    "                # Check if the next line is \"pass\" and treat it as a subheadline if it is\n",
    "                if len(table_data) > 0 and table_data[0] == [\"PASS\"]:\n",
    "                    elements.append(Paragraph(\" \".join(table_data[0]), pass_style))\n",
    "                    elements.append(Spacer(1, 12))\n",
    "                    table_data = table_data[1:]  # Remove the \"pass\" row\n",
    "            else:\n",
    "                subheadline = table_data[1]\n",
    "                if (\"Missing_value_mandatory\" in headline[0] or \"Duplication\" in headline[0] or \"Non_discerning_info\" in headline[0]) and subheadline != [\"PASS\"]:\n",
    "                    elements.append(Paragraph(\" \".join(headline), error_style))\n",
    "                else:\n",
    "                    # if headline is Missing_value_optional\n",
    "                    if \"Missing_value_optional\" in headline[0]:\n",
    "                        # check weather there are any numbers in the table_data\n",
    "                        has_numbers = any(isinstance(convert_to_number(cell), (int, float)) for row in table_data for cell in row)\n",
    "                        if has_numbers:\n",
    "                            elements.append(Paragraph(\" \".join(headline), error_style))\n",
    "                        else:\n",
    "                            elements.append(Paragraph(\" \".join(headline), headline_style))\n",
    "                    else:\n",
    "                        elements.append(Paragraph(\" \".join(headline), headline_style))\n",
    "                table_data = table_data[1:]  # Remove only the headline row\n",
    "            \n",
    "            # Create the table without the headline (and subheadline) rows\n",
    "            if len(table_data) == 0:\n",
    "                draw_line(elements)\n",
    "                continue\n",
    "\n",
    "            # Define padding\n",
    "            padding = 48  # Adjust this value as needed\n",
    "\n",
    "            # Calculate the width of each column\n",
    "            page_width = letter[0]  # Width of the letter page size\n",
    "            adjusted_page_width = page_width - (2 * padding)  # Subtract padding from both sides\n",
    "            num_columns = len(table_data[0])  # Number of columns in the table\n",
    "            col_width = adjusted_page_width / num_columns  # Width of each column\n",
    "            \n",
    "            # Wrap cell content in Paragraphs to enable word wrapping\n",
    "            table_data = [[Paragraph(cell, body_style) for cell in row] for row in table_data]\n",
    "\n",
    "                        # if headline is Missing_value_optional\n",
    "            if \"Missing_value\" in headline[0]:\n",
    "                # go trough all values and if value is a number then color it differently\n",
    "                for i, row in enumerate(table_data):\n",
    "                    for j, cell in enumerate(row):\n",
    "                        if isinstance(convert_to_number(cell.getPlainText()), (int, float)):\n",
    "                                # table.setStyle(TableStyle([('TEXTCOLOR', (j, i), (j, i), colors.HexColor(\"#FFC80F\"))]))\n",
    "                                table_data[i][j] = Paragraph(cell.getPlainText(), body_style_err)\n",
    "\n",
    "            # Create the table with equal column widths\n",
    "            table = Table(table_data, colWidths=[col_width] * num_columns)\n",
    "            \n",
    "            # Add style to the table\n",
    "            style = TableStyle([\n",
    "                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#212223')),\n",
    "                ('TEXTCOLOR', (0, 0), (-1, 0), colors.HexColor(\"#E9E9E9\")),\n",
    "                ('TEXTCOLOR', (0, 0), (-1, -1), colors.HexColor(\"#E9E9E9\")),\n",
    "                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "                \n",
    "                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "                ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "                \n",
    "                ('BOTTOMPADDING', (0, 0), (-1, 0), 4),\n",
    "\t\t\t\t('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.HexColor('#131415'), colors.HexColor('#18191A') ]),\n",
    "                ('LINEBEFORE', (1, 0), (-1, -1), 1, colors.HexColor('#2F3031')),  # Vertical lines before each column\n",
    "\n",
    "                ('WORDWRAP', (0, 0), (-1, -1), 'CJK'),  # Enable word wrap for all cells\n",
    "            ])\n",
    "            table.setStyle(style)\n",
    "\n",
    "\n",
    "            \n",
    "            elements.append(table)\n",
    "            \n",
    "            # if it is repetition add graph\n",
    "            if \"Repetition\" in headline[0]:\n",
    "                graph_png_path = find_png_file(f\"{FOLDER_PATH}/REPETITION\", headline[0])[0]\n",
    "                add_graph_image(elements, graph_png_path)\n",
    "\n",
    "\n",
    "            elements.append(Spacer(1, 16))  # Add some space after the line\n",
    "            draw_line(elements)\n",
    "\n",
    "    pdf = SimpleDocTemplate(\n",
    "        fname,\n",
    "        leftMargin=padding-16,\n",
    "        rightMargin=padding-16,\n",
    "        topMargin=padding-16,\n",
    "        bottomMargin=padding-16\n",
    "    )\n",
    "\n",
    "    # Define a custom PageTemplate with a background color\n",
    "    def add_background(canvas, doc):\n",
    "        canvas.saveState()\n",
    "        canvas.setFillColor(colors.HexColor('#131415'))\n",
    "        canvas.rect(0, 0, letter[0], letter[1] + 64, fill=1)\n",
    "        canvas.restoreState()\n",
    "\n",
    "    frame = Frame(pdf.leftMargin, pdf.bottomMargin, pdf.width, pdf.height, id='normal')\n",
    "    template = PageTemplate(id='background', frames=frame, onPage=add_background)\n",
    "    pdf.addPageTemplates([template])\n",
    "    \n",
    "    # Build the PDF\n",
    "    pdf.build(elements, onFirstPage=add_background, onLaterPages=add_background)\n",
    "\n",
    "def add_graph_image(elements, path):\n",
    "    elements.append(Image(path, width=600, height=400))\n",
    "\n",
    "def draw_line(elements):\n",
    "    # Add a horizontal line after the table\n",
    "    elements.append(Spacer(1, 6))  # Add some space after the line\n",
    "    # Get the width of the page\n",
    "    page_width = letter[0]\n",
    "    # Create a line that spans the full width of the page\n",
    "    line = Drawing(page_width, 1)\n",
    "    gray_line = Line(-64, 0, page_width, 0)  # Set the length of the line to the page width\n",
    "    gray_line.strokeColor = colors.HexColor(\"#2F3031\")  # Set the line color to gray\n",
    "    line.add(gray_line)\n",
    "    elements.append(line)\n",
    "    elements.append(Spacer(1, 6))  # Add some space after the line\n",
    "\n",
    "def find_png_file(folder_path, headline):\n",
    "    # Use glob to find all PNG files in the specified folder\n",
    "    png_files = glob.glob(os.path.join(folder_path, '*.png'))\n",
    "     # Filter the files to find those that contain the headline in their path\n",
    "    matching_files = [png_file for png_file in png_files if headline in os.path.basename(png_file)]\n",
    "    \n",
    "    return matching_files\n",
    "\n",
    "def convert_to_number(cell):\n",
    "    try:\n",
    "        # Try to convert to integer\n",
    "        return int(cell)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # If integer conversion fails, try to convert to float\n",
    "            return float(cell)\n",
    "        except ValueError:\n",
    "            # If both conversions fail, return the original string\n",
    "            return cell\n",
    "save_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_files(directory):\n",
    "    # Go through directory and split files\n",
    "    # fname = f'{FOLDER_PATH}/Report-{filename}-{CURRENT_DATE}.csv'\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            # check whether the file ending is csv\n",
    "            if f[-3:] == \"csv\":\n",
    "                # print(f)\n",
    "                # check size of the file\n",
    "                if os.path.getsize(f) > 50000000:\n",
    "                    print(f'splitting : {filename}')\n",
    "                    # make chunk out of big page\n",
    "                    chunkFolder = f\"{directory}/{filename[:-4]}/\"\n",
    "                    if not os.path.exists(chunkFolder):\n",
    "                        os.mkdir(chunkFolder)\n",
    "                    for i,chunk in enumerate(pd.read_csv(f, chunksize=250000)):\n",
    "                        chunk.to_csv(chunkFolder+f'{filename[:-4]}'+'-{}.csv'.format(i), index=False)\n",
    "                        print(i)\n",
    "                    # remove file from the system\n",
    "                    os.remove(f)\n",
    "        if os.path.isdir(f):\n",
    "            split_files(f)\n",
    "split_files(FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only make an archive if zip is True\n",
    "if zip:\n",
    "    shutil.make_archive(folder_to_download, 'zip', folder_to_download)\n",
    "    filelink = folder_to_download+'.zip'\n",
    "    FileLink(filelink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------+\n",
      "| Name                    | Value |\n",
      "+-------------------------+-------+\n",
      "| Duplication             | \u001b[1;31;40mFIX\u001b[0m   |\n",
      "| Non_discerning_info     | \u001b[1;31;40mFIX\u001b[0m   |\n",
      "| Missing_value_mandatory | \u001b[1;31;40mFIX\u001b[0m   |\n",
      "| Repetition_1            | FIX   |\n",
      "| Repetition_2            | FIX   |\n",
      "| Repetition_4            | FIX   |\n",
      "| Formatting_2            | \u001b[1;31;40mFIX\u001b[0m   |\n",
      "| Formatting_3            | \u001b[1;31;40mFIX\u001b[0m   |\n",
      "| Formatting_4            | \u001b[1;31;40mFIX\u001b[0m   |\n",
      "| Formatting_5            | \u001b[1;31;40mFIX\u001b[0m   |\n",
      "| Formatting_6            | \u001b[1;31;40mFIX\u001b[0m   |\n",
      "| Formatting_7            | \u001b[1;31;40mFIX\u001b[0m   |\n",
      "| Formatting_8            | \u001b[1;31;40mFIX\u001b[0m   |\n",
      "+-------------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "# Column headers\n",
    "headers = [\"Name\", \"Value\"]\n",
    "colalign = (\"left\", \"left\")\n",
    "print(tabulate(CMD_TABLE, headers, tablefmt=\"pretty\", colalign=colalign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
